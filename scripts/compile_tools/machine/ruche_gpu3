#
# Machine file for RUCHE
# __________________________________________________________
#
# Documentation:
#https://mesocentre.pages.centralesupelec.fr/user_doc/ruche/01_cluster_overview/

# Compile command: make -j 40  machine="ruche_gpu2" config="gpu_nvidia noopenmp detailed_timers verbose"

SMILEICXX_DEPS = g++ -I/gpfs/users/prouveurc/tools/hdf5_nvhpc24/hdfsrc/install/include/   #nvcc -I/gpfs/softs/spack_0.17/opt/spack/linux-centos7-haswell/nvhpc-23.7/openmpi-4.1.5-ckfuippq6gf6qsilwitd7d2zyd5bng32/include/ -I/gpfs/softs/spack_0.17/opt/spack/linux-centos7-haswell/nvhpc-23.7/hdf5-1.12.0-3em63nl4p5tmv37offfmuvz2uswvgwzv/include/

GPU_COMPILER = nvcc -I/gpfs/users/prouveurc/tools/Linux_x86_64/24.5/comm_libs/12.4/openmpi4/openmpi-4.1.5/include -I/gpfs/users/prouveurc/tools/hdf5_nvhpc24/hdfsrc/install/include/  #-I/gpfs/softs/spack_0.17/opt/spack/linux-centos7-haswell/nvhpc-23.7/hdf5-1.12.0-3em63nl4p5tmv37offfmuvz2uswvgwzv/include/

CXXFLAGS += -w
# IDRIS config for curand
CXXFLAGS += -acc=gpu -gpu=cc80 #-lcurand   #-gpu=cuda12.4 -std=c++14  -lcurand #-ta=tesla:cc70 -std=c++14  -lcurand -cudalib=curand # do not put -cuda here
# CXXFLAGS += --expt-relaxed-constexpr

#ACCELERATOR_CUDA_FLAGS += -w -gpu=cc70,cc80 -cuda -std=c++14  -lcurand #not used at the moment


GPU_COMPILER_FLAGS += -O3 --std c++14

GPU_COMPILER_FLAGS += --expt-relaxed-constexpr
GPU_COMPILER_FLAGS += -arch=sm_80  #-gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 # -arch=sm_70 #sm_89 # first compile completely with sm_80 then rm build/src/Projector/Projector3D2OrderGPUKernelCUDAHIP.o then compile again with sm_89 (no make clean !) #adapt for 2D  
CXXFLAGS        += -Minfo=accel # what is offloaded/copied
# CXXFLAGS        += -Minfo=all   # very verbose output

# To turn on the OpenMP support, uncomment these 3 lines and comment the line just above defining 'SMILEI_ACCELERATOR_GPU_OACC'
# CXXFLAGS        += -mp=gpu -DSMILEI_ACCELERATOR_GPU_OMP
# GPU_COMPILER_FLAGS +=         -DSMILEI_ACCELERATOR_GPU_OMP # Can't we pass the -mp=gpu to nvcc when compiling a .cu file ?
# LDFLAGS                      += -mp=gpu

LDFLAGS += -L/gpfs/softs/spack_0.17/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/gettext-0.21-bppg5g6ijfrvi7sdylhhg3t5f6v2fh2x/lib/ -L/gpfs/users/prouveurc/tools/hdf5_nvhpc24/hdfsrc/install/lib -L/gpfs/users/prouveurc/tools/Linux_x86_64/24.5/math_libs/lib64/ #-L/gpfs/softs/spack_0.17/opt/spack/linux-centos7-haswell/nvhpc-23.7/hdf5-1.12.0-3em63nl4p5tmv37offfmuvz2uswvgwzv/lib
LDFLAGS +=  -acc=gpu -gpu=cc80 -cuda -cudalib=curand #-lcurand 
CXXFLAGS += -D__GCC_ATOMIC_TEST_AND_SET_TRUEVAL=1  -std=c++14 


############################################
#  example of a job script
############################################

#!/bin/bash
#
##SBATCH --job-name=validation_smilei
##SBATCH --output=%x.o%j 
##SBATCH --time=00:20:00 
##SBATCH --ntasks=1                   # Number of MPI processes (= total number of GPU)
##SBATCH --ntasks-per-node=1          # nombre de tache MPI par noeud (= nombre de GPU par noeud)
##SBATCH --gres=gpu:1
##SBATCH --partition=gpu_test
#
## Load necessary modules
#source /gpfs/users/prouveurc/env_smilei.sh
#module load anaconda3/2022.10/gcc-11.2.0
#
## Run cuda code
#LD_PRELOAD=/gpfs/softs/spack/opt/spack/linux-centos7-haswell/gcc-4.8.5/gcc-11.2.0-mpv3i3uebzvnvz7wxn6ywysd5hftycj3/lib64/libstdc++.so.6.0.29 ./smilei input.py
#
#

